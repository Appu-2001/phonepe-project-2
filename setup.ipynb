{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d9505d-9f30-4548-9b78-d7d26f478471",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1245cd-5327-4f77-b83f-84888e176f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and modules\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mysql.connector as sql\n",
    "\n",
    "# import project environment\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee691d3-ea1c-44cb-ac09-e4fce52834e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38c410-a76d-4c36-af8f-e4a2b506ea08",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Dataframe of transaction - aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee04b44-e217-4a7d-87a0-b9c6e260c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of states\n",
    "transaction_aggregate_list = os.listdir(env.project_transaction_aggregate_dir)\n",
    "\n",
    "transaction_aggregate_columns = {\n",
    "    \"State\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quarter\": [],\n",
    "    \"Transaction_type\": [],\n",
    "    \"Transaction_count\": [],\n",
    "    \"Transaction_amount\": [],\n",
    "}\n",
    "\n",
    "# iterating states\n",
    "for state in transaction_aggregate_list:\n",
    "    current_state = os.path.join(env.project_transaction_aggregate_dir, state)\n",
    "    aggregate_year_list = os.listdir(current_state)\n",
    "\n",
    "    # iterating years in a state\n",
    "    for year in aggregate_year_list:\n",
    "        current_year = os.path.join(current_state, year)\n",
    "        aggregate_file_list = os.listdir(current_year)\n",
    "\n",
    "        # iterating quarter data in a year\n",
    "        for file in aggregate_file_list:\n",
    "            current_file = os.path.join(current_year, file)\n",
    "\n",
    "            # load file as json data\n",
    "            data = open(current_file, \"r\")\n",
    "            A = json.load(data)\n",
    "\n",
    "            # iterate json data\n",
    "            for i in A[\"data\"][\"transactionData\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                transaction_aggregate_columns[\"Transaction_type\"].append(name)\n",
    "                transaction_aggregate_columns[\"Transaction_count\"].append(count)\n",
    "                transaction_aggregate_columns[\"Transaction_amount\"].append(amount)\n",
    "                transaction_aggregate_columns[\"State\"].append(state)\n",
    "                transaction_aggregate_columns[\"Year\"].append(year)\n",
    "                transaction_aggregate_columns[\"Quarter\"].append(\n",
    "                    int(file.strip(\".json\"))\n",
    "                )\n",
    "\n",
    "df_transaction_aggregate = pd.DataFrame(transaction_aggregate_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8afac9e-7bde-42da-84d5-41b18aa06b5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Dataframe of transaction - map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40224222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of states\n",
    "transaction_map_list = os.listdir(env.project_transaction_map_dir)\n",
    "\n",
    "transaction_map_columns = {\n",
    "    \"State\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quarter\": [],\n",
    "    \"District\": [],\n",
    "    \"Count\": [],\n",
    "    \"Amount\": [],\n",
    "}\n",
    "\n",
    "# iterating states\n",
    "for state in transaction_map_list:\n",
    "    current_state = os.path.join(env.project_transaction_map_dir, state)\n",
    "    map_year_list = os.listdir(current_state)\n",
    "\n",
    "    # iterating years in a state\n",
    "    for year in map_year_list:\n",
    "        current_year = os.path.join(current_state, year)\n",
    "        map_file_list = os.listdir(current_year)\n",
    "\n",
    "        # iterating quarter data in a year\n",
    "        for file in map_file_list:\n",
    "            current_file = os.path.join(current_year, file)\n",
    "\n",
    "            # load file as json data\n",
    "            data = open(current_file, \"r\")\n",
    "            B = json.load(data)\n",
    "\n",
    "            # iterate json data\n",
    "            for i in B[\"data\"][\"hoverDataList\"]:\n",
    "                district = i[\"name\"]\n",
    "                count = i[\"metric\"][0][\"count\"]\n",
    "                amount = i[\"metric\"][0][\"amount\"]\n",
    "                transaction_map_columns[\"District\"].append(district)\n",
    "                transaction_map_columns[\"Count\"].append(count)\n",
    "                transaction_map_columns[\"Amount\"].append(amount)\n",
    "                transaction_map_columns[\"State\"].append(state)\n",
    "                transaction_map_columns[\"Year\"].append(year)\n",
    "                transaction_map_columns[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "df_transaction_map = pd.DataFrame(transaction_map_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d215bb",
   "metadata": {},
   "source": [
    "##### Dataframe of transaction - top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7254016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of states\n",
    "transaction_top_list = os.listdir(env.project_transaction_top_dir)\n",
    "\n",
    "transaction_top_columns = {\n",
    "    \"State\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quarter\": [],\n",
    "    \"Pincode\": [],\n",
    "    \"Transaction_count\": [],\n",
    "    \"Transaction_amount\": [],\n",
    "}\n",
    "\n",
    "# iterating states\n",
    "for state in transaction_top_list:\n",
    "    current_state = os.path.join(env.project_transaction_top_dir, state)\n",
    "    top_year_list = os.listdir(current_state)\n",
    "\n",
    "    # iterating years in a state\n",
    "    for year in top_year_list:\n",
    "        current_year = os.path.join(current_state, year)\n",
    "        top_file_list = os.listdir(current_year)\n",
    "\n",
    "        # iterating quarter data in a year\n",
    "        for file in top_file_list:\n",
    "            current_file = os.path.join(current_year, file)\n",
    "\n",
    "            # load file as json data\n",
    "            data = open(current_file, \"r\")\n",
    "            C = json.load(data)\n",
    "\n",
    "            # iterate json data\n",
    "            for i in C[\"data\"][\"pincodes\"]:\n",
    "                name = i[\"entityName\"]\n",
    "                count = i[\"metric\"][\"count\"]\n",
    "                amount = i[\"metric\"][\"amount\"]\n",
    "                transaction_top_columns[\"Pincode\"].append(name)\n",
    "                transaction_top_columns[\"Transaction_count\"].append(count)\n",
    "                transaction_top_columns[\"Transaction_amount\"].append(amount)\n",
    "                transaction_top_columns[\"State\"].append(state)\n",
    "                transaction_top_columns[\"Year\"].append(year)\n",
    "                transaction_top_columns[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "df_transaction_top = pd.DataFrame(transaction_top_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf49bb-36b8-4fe4-adbc-fa3d58656020",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Dataframe of user - aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd40f2d-b882-4473-8cec-a2be159c6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of states\n",
    "user_aggregate_list = os.listdir(env.project_user_aggregate_dir)\n",
    "\n",
    "user_aggregate_columns = {\n",
    "    \"State\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quarter\": [],\n",
    "    \"Brands\": [],\n",
    "    \"Count\": [],\n",
    "    \"Percentage\": [],\n",
    "}\n",
    "\n",
    "# iterating states\n",
    "for state in user_aggregate_list:\n",
    "    current_state = os.path.join(env.project_user_aggregate_dir, state)\n",
    "    aggregate_year_list = os.listdir(current_state)\n",
    "\n",
    "    # iterating years in a state\n",
    "    for year in aggregate_year_list:\n",
    "        current_year = os.path.join(current_state, year)\n",
    "        aggregate_file_list = os.listdir(current_year)\n",
    "\n",
    "        # iterating quarter data in a year\n",
    "        for file in aggregate_file_list:\n",
    "            current_file = os.path.join(current_year, file)\n",
    "\n",
    "            # load file as json data\n",
    "            data = open(current_file, \"r\")\n",
    "            D = json.load(data)\n",
    "\n",
    "            # iterate json data\n",
    "            try:\n",
    "                for i in D[\"data\"][\"usersByDevice\"]:\n",
    "                    brand_name = i[\"brand\"]\n",
    "                    counts = i[\"count\"]\n",
    "                    percents = i[\"percentage\"]\n",
    "                    user_aggregate_columns[\"Brands\"].append(brand_name)\n",
    "                    user_aggregate_columns[\"Count\"].append(counts)\n",
    "                    user_aggregate_columns[\"Percentage\"].append(percents)\n",
    "                    user_aggregate_columns[\"State\"].append(state)\n",
    "                    user_aggregate_columns[\"Year\"].append(year)\n",
    "                    user_aggregate_columns[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "df_user_aggregate = pd.DataFrame(user_aggregate_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc01c56-3e33-4623-9cb3-58c47f1aaa39",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Dataframe of user - map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21de8c92-7c89-4ac6-adf0-2fd200bcd55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of states\n",
    "user_map_list = os.listdir(env.project_user_map_dir)\n",
    "\n",
    "user_map_columns = {\n",
    "    \"State\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quarter\": [],\n",
    "    \"District\": [],\n",
    "    \"RegisteredUser\": [],\n",
    "    \"AppOpens\": [],\n",
    "}\n",
    "\n",
    "# iterating states\n",
    "for state in user_map_list:\n",
    "    current_state = os.path.join(env.project_user_map_dir, state)\n",
    "    map_year_list = os.listdir(current_state)\n",
    "\n",
    "    # iterating years in a state\n",
    "    for year in map_year_list:\n",
    "        current_year = os.path.join(current_state, year)\n",
    "        map_file_list = os.listdir(current_year)\n",
    "\n",
    "        # iterating quarter data in a year\n",
    "        for file in map_file_list:\n",
    "            current_file = os.path.join(current_year, file)\n",
    "\n",
    "            # load file as json data\n",
    "            data = open(current_file, \"r\")\n",
    "            E = json.load(data)\n",
    "\n",
    "            # iterate json data\n",
    "            for i in E[\"data\"][\"hoverData\"].items():\n",
    "                district = i[0]\n",
    "                registereduser = i[1][\"registeredUsers\"]\n",
    "                appOpens = i[1][\"appOpens\"]\n",
    "                user_map_columns[\"District\"].append(district)\n",
    "                user_map_columns[\"RegisteredUser\"].append(registereduser)\n",
    "                user_map_columns[\"AppOpens\"].append(appOpens)\n",
    "                user_map_columns[\"State\"].append(state)\n",
    "                user_map_columns[\"Year\"].append(year)\n",
    "                user_map_columns[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "df_user_map = pd.DataFrame(user_map_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6826c6d-cc47-4188-b48f-641142970769",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Dataframe of user - top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d32db2-5028-4da2-9d84-c7cab299c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of states\n",
    "user_top_list = os.listdir(env.project_user_top_dir)\n",
    "\n",
    "user_top_columns = {\n",
    "    \"State\": [],\n",
    "    \"Year\": [],\n",
    "    \"Quarter\": [],\n",
    "    \"Pincode\": [],\n",
    "    \"RegisteredUsers\": [],\n",
    "}\n",
    "\n",
    "# iterating states\n",
    "for state in user_top_list:\n",
    "    current_state = os.path.join(env.project_user_top_dir, state)\n",
    "    top_year_list = os.listdir(current_state)\n",
    "\n",
    "    # iterating years in a state\n",
    "    for year in top_year_list:\n",
    "        current_year = os.path.join(current_state, year)\n",
    "        top_file_list = os.listdir(current_year)\n",
    "\n",
    "        # iterating quarter data in a year\n",
    "        for file in top_file_list:\n",
    "            current_file = os.path.join(current_year, file)\n",
    "\n",
    "            # load file as json data\n",
    "            data = open(current_file, \"r\")\n",
    "            F = json.load(data)\n",
    "\n",
    "            # iterate json data\n",
    "            for i in F[\"data\"][\"pincodes\"]:\n",
    "                name = i[\"name\"]\n",
    "                registeredUsers = i[\"registeredUsers\"]\n",
    "                user_top_columns[\"Pincode\"].append(name)\n",
    "                user_top_columns[\"RegisteredUsers\"].append(registeredUsers)\n",
    "                user_top_columns[\"State\"].append(state)\n",
    "                user_top_columns[\"Year\"].append(year)\n",
    "                user_top_columns[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "df_user_top = pd.DataFrame(user_top_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef47900-8e16-43ae-bc6e-91c41bfe6008",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Dataframe as CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b0d942-b868-40f2-b6e4-5b641ba03bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming transaction data\n",
    "df_transaction_aggregate.to_csv(env.project_csv_transaction_aggregate, index=False)\n",
    "df_transaction_map.to_csv(env.project_csv_transaction_map, index=False)\n",
    "df_transaction_top.to_csv(env.project_csv_transaction_top, index=False)\n",
    "\n",
    "# transforming user data\n",
    "df_user_aggregate.to_csv(env.project_csv_user_aggregate, index=False)\n",
    "df_user_map.to_csv(env.project_csv_user_map, index=False)\n",
    "df_user_top.to_csv(env.project_csv_user_top, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afc952-7d23-48d5-8b81-5278cebf388f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Managing database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2361f-124d-408e-b81e-f6aa663b5d4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Connecting to MySQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d50487-be1f-4c46-94bd-dd973fe6f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating connection\n",
    "db_connection = sql.connect(\n",
    "    host=env.sql_hostname, user=env.sql_username, password=env.sql_password\n",
    ")\n",
    "\n",
    "# creating cursor to execute queries\n",
    "db_cursor = db_connection.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c12889-3681-40ef-afe3-e2572afa2cc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Creating new database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feda9ef1-6484-49ed-a354-1fae48867f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating database\n",
    "db_cursor.execute(\"CREATE DATABASE IF NOT EXISTS \" + env.sql_database)\n",
    "\n",
    "# running queries in new database\n",
    "db_cursor.execute(\"USE \" + env.sql_database)\n",
    "\n",
    "# the connection is not auto committed by default, so we must commit to save our changes\n",
    "db_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1e242",
   "metadata": {},
   "source": [
    "### Migrating transaction dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c7c46-9cb0-4fe3-9f5f-802a94f148d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Migrating aggregate data to table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbdd838b-378c-4b0f-969a-a126a97bf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table\n",
    "db_cursor.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS \"\n",
    "    + env.sql_table_transaction_aggregate\n",
    "    + \" (State varchar(100), Year int, Quarter int, Transaction_type varchar(100), Transaction_count int, Transaction_amount double)\"\n",
    ")\n",
    "\n",
    "# iterating all rows in dataframe to insert data\n",
    "for i, row in df_transaction_aggregate.iterrows():\n",
    "    sql = (\n",
    "        \"INSERT INTO \"\n",
    "        + env.sql_table_transaction_aggregate\n",
    "        + \" VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    )\n",
    "    db_cursor.execute(sql, tuple(row))\n",
    "\n",
    "# the connection is not auto committed by default, so we must commit to save our changes\n",
    "db_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789caefe-39d3-4c41-80be-844701b6d5c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Migrating map data to table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d58ba1b2-ff3f-4eb2-b193-d1ff8d9d9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table\n",
    "db_cursor.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS \"\n",
    "    + env.sql_table_transaction_map\n",
    "    + \" (State varchar(100), Year int, Quarter int, District varchar(100), Count int, Amount double)\"\n",
    ")\n",
    "\n",
    "# iterating all rows in dataframe to insert data\n",
    "for i, row in df_transaction_map.iterrows():\n",
    "    sql = \"INSERT INTO \" + env.sql_table_transaction_map + \" VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    db_cursor.execute(sql, tuple(row))\n",
    "\n",
    "# the connection is not auto committed by default, so we must commit to save our changes\n",
    "db_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25506714-b67c-4d96-a8cd-57eb390bfadb",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Migrating top data to table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f80c00-e218-4c24-8a07-861480cf28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table\n",
    "db_cursor.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS \"\n",
    "    + env.sql_table_transaction_top\n",
    "    + \" (State varchar(100), Year int, Quarter int, Pincode int, Transaction_count int, Transaction_amount double)\"\n",
    ")\n",
    "\n",
    "# iterating all rows in dataframe to insert data\n",
    "for i, row in df_transaction_top.iterrows():\n",
    "    sql = \"INSERT INTO \" + env.sql_table_transaction_top + \" VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    db_cursor.execute(sql, tuple(row))\n",
    "\n",
    "# the connection is not auto committed by default, so we must commit to save our changes\n",
    "db_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527d0d6",
   "metadata": {},
   "source": [
    "### Migrating user dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de1509-7e8c-4ba6-b8ec-e4cddcee41f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Migrating aggregate data to table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff0f9395-98b1-4c84-9d48-1f7f8c40a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table\n",
    "db_cursor.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS \"\n",
    "    + env.sql_table_user_aggregate\n",
    "    + \" (State varchar(100), Year int, Quarter int, Brands varchar(100), Count int, Percentage double)\"\n",
    ")\n",
    "\n",
    "# iterating all rows in dataframe to insert data\n",
    "for i, row in df_user_aggregate.iterrows():\n",
    "    sql = \"INSERT INTO \" + env.sql_table_user_aggregate + \" VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    db_cursor.execute(sql, tuple(row))\n",
    "\n",
    "# the connection is not auto committed by default, so we must commit to save our changes\n",
    "db_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e603b7aa-162a-41ee-88f3-f7be1de541a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Migrating map data to table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b1e3f-81e7-4131-ba86-f86dd170faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table\n",
    "db_cursor.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS \"\n",
    "    + env.sql_table_user_map\n",
    "    + \" (State varchar(100), Year int, Quarter int, District varchar(100), Registered_user int, App_opens int)\"\n",
    ")\n",
    "\n",
    "# iterating all rows in dataframe to insert data\n",
    "for i, row in df_user_map.iterrows():\n",
    "    sql = \"INSERT INTO \" + env.sql_table_user_map + \" VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "    db_cursor.execute(sql, tuple(row))\n",
    "\n",
    "# the connection is not auto committed by default, so we must commit to save our changes\n",
    "db_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb8659d-a1bf-494d-bf85-f8279e5b0a06",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Migrating top data to table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20dd8b-61ce-4148-8bcf-bceb30cb79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table\n",
    "db_cursor.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS \"\n",
    "    + env.sql_table_user_top\n",
    "    + \" (State varchar(100), Year int, Quarter int, Pincode int, Registered_users int)\"\n",
    ")\n",
    "\n",
    "# iterating all rows in dataframe to insert data\n",
    "for i, row in df_user_top.iterrows():\n",
    "    sql = \"INSERT INTO \" + env.sql_table_user_top + \" VALUES (%s,%s,%s,%s,%s)\"\n",
    "    db_cursor.execute(sql, tuple(row))\n",
    "\n",
    "# the connection is not auto committed by default, so we must commit to save our changes\n",
    "db_connection.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
